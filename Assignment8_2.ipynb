{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Load the dataset used at 8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset : \n",
    "import pandas as pd\n",
    "wine = pd.read_csv('./datasets/wine/wine.csv')\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=wine.drop(['style'],axis=1)\n",
    "y=wine['style']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder=LabelEncoder()\n",
    "y = labelencoder.fit_transform(y)\n",
    "X=X.values\n",
    "#training set & test set 나누기\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Pre-process the dataset using PCA algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "import time\n",
    "class PCA_model:\n",
    "    def __init__(self,X,n):\n",
    "        #PCA\n",
    "        self.pca = PCA(n_components= n)\n",
    "        self.PCA_time = time.time()\n",
    "        self.X_PCA = self.pca.fit_transform(X)\n",
    "        self.PCA_time = time.time() - self.PCA_time\n",
    "        \n",
    "        #IncrementalPCA\n",
    "        self.n_batches=2\n",
    "        self.inc_pca =IncrementalPCA(n_components=n)\n",
    "        self.IPCA_time = time.time()\n",
    "        for X_batch in np.array_split(X,self.n_batches):\n",
    "            self.inc_pca.partial_fit(X_batch)\n",
    "        self.X_IPCA = self.inc_pca.transform(X)\n",
    "        self.IPCA_time = time.time() - self.IPCA_time\n",
    "        \n",
    "        #Randomized PCA\n",
    "        self.rnd_pca = PCA(n_components= n,svd_solver='randomized')\n",
    "        self.X_RPCA = rnd_pca.fit_transform(X)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def getTime(self):\n",
    "        print('PCA fit_transform time : ',self.PCA_time)\n",
    "        print('IPCA fit_transform time : ',self.IPCA_time)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "\n",
    "pca_2 = PCA(n_components=2)\n",
    "pca_4 = PCA(n_components=4)\n",
    "pca_6 = PCA(n_components=6)\n",
    "X_PCA_2 = pca_2.fit_transform(X)\n",
    "X_PCA_4 = pca_4.fit_transform(X)\n",
    "X_PCA_6 = pca_6.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IncrementalPCA\n",
    "\n",
    "n_batches = 2\n",
    "inc_pca_2 = IncrementalPCA(n_components=2)\n",
    "inc_pca_4 = IncrementalPCA(n_components=4)\n",
    "inc_pca_6 = IncrementalPCA(n_components=6)\n",
    "\n",
    "for X_batch in np.array_split(X,n_batches):\n",
    "    inc_pca_2.partial_fit(X_batch)\n",
    "    inc_pca_4.partial_fit(X_batch)\n",
    "    inc_pca_6.partial_fit(X_batch)\n",
    "X_IPCA_2 = inc_pca_2.transform(X)\n",
    "X_IPCA_4 = inc_pca_4.transform(X)\n",
    "X_IPCA_6 = inc_pca_6.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized PCA\n",
    "rnd_pca_2 = PCA(n_components=2,svd_solver='randomized')\n",
    "rnd_pca_4 = PCA(n_components=4,svd_solver='randomized')\n",
    "rnd_pca_6 = PCA(n_components=6,svd_solver='randomized')\n",
    "X_RPCA_2 = rnd_pca_2.fit_transform(X)\n",
    "X_RPCA_4 = rnd_pca_4.fit_transform(X)\n",
    "X_RPCA_6 = rnd_pca_6.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Train a model using each reduced dimensionality dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Compare each model's perfomance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
